{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI 535/635: Management & Processing of Large-scale Data\n",
    "\n",
    "#### Author: Michael Mooney (mooneymi@ohsu.edu)\n",
    "\n",
    "## Week 3: Data Storage and Querying Solutions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Learning Objectives\n",
    "3. Resource Profiling\n",
    "4. Review of Basic Python Data Types\n",
    "5. Data from dbSNP\n",
    "6. Connecting to Relational DBs\n",
    "7. Pandas\n",
    "8. Bcolz and bdot\n",
    "9. HDF5 (PyTables)\n",
    "\n",
    "Requirements:\n",
    "- Python modules:\n",
    "    - `os`\n",
    "    - `time`\n",
    "    - `timeit`\n",
    "    - `memory_profiler`\n",
    "    - `shutil`\n",
    "    - `numpy`\n",
    "    - `pandas`\n",
    "    - `bcolz`\n",
    "    - `bdot`\n",
    "    - `pytables (tables)`\n",
    "    - `pymysql`\n",
    "- Data files:\n",
    "    - dbSNP annotations (chromosome 1 only): `./data/chr1_reducedCols.txt.gz`\n",
    "    - A MySQL config file containing connection parameters: `mysqlconfig.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bcolz\n",
    "import bdot\n",
    "import tables\n",
    "import pymysql as pym\n",
    "import pymysql.cursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below are some common problems encountered when working with large datasets.\n",
    "\n",
    "1. Data does not fit into memory\n",
    "    - In particular, this can be a problem when setting up parallel computations, where each process needs the full data\n",
    "2. Accessing (querying) the data is slow\n",
    "3. Data files on-disk are very large (i.e. not easily portable)\n",
    "\n",
    "Potential Solutions:\n",
    "\n",
    "1. Use on-disk storage that is optimized for fast read/write access\n",
    "2. Use data storage that allows for multiple concurrent reads (i.e. can be shared across multiple processes)\n",
    "3. Use data compression\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. You will learn some basic methods for profiling the amount of resources and time used by computational tasks\n",
    "2. You will learn how store large datasets in various \"high-performance\" Python data structures\n",
    "3. You will learn how to query data in each of the data structures\n",
    "4. You will learn how to convert between these various data storage solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: this is not a python command (only needed in the Jupyter notebook)\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.126 seconds\n",
      " Memory used: 153.695 Mb\n"
     ]
    }
   ],
   "source": [
    "## A dummy function that creates a large list\n",
    "def foo(a, n=100):\n",
    "    time.sleep(2)\n",
    "    b = [a] * n\n",
    "    time.sleep(1)\n",
    "    return None\n",
    "\n",
    "## Use the time and memory_profiler modules to profile the foo function\n",
    "t0 = time.time()\n",
    "mem1 = memory_usage((foo, (1,10000000)), max_usage=True, timestamps=True)[0]\n",
    "print \"Elapsed time: %.3f seconds\\n Memory used: %.3f Mb\" % (mem1[1]-t0, mem1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0711960792541504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile foo\n",
    "timeit.timeit('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.078933000564575, 3.0812008380889893, 3.0734341144561768]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use timeit to profile multiple function calls\n",
    "## Default is 3 repeats (repeat=3)\n",
    "timeit.repeat('foo(1,10000000)', setup='from __main__ import foo', number=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: in a Jupyter notebook the %memit, %time, and %timeit magics are available\n",
    "\n",
    "Use the following to see the docstrings:\n",
    "\n",
    "%memit?\n",
    "\n",
    "%time?\n",
    "\n",
    "%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 153.79 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.8 ms, sys: 14.6 ms, total: 77.4 ms\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%time foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.08 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r 3 foo(1, 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Note: Be cautious when using these Jupyter magics when doing things such as opening files, it is possible your code will be executed multiple times which could cause problems (i.e. multiple open file handles).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of Basic Python Data Types\n",
    "\n",
    "Basic Python data types and when to use them:\n",
    "\n",
    "**Lists/Tuples**: Use these when you need to iterate over a collection of items.\n",
    "\n",
    "**Dictionaries**: Use these when you need to repeatedly access individual data elements (e.g. searching by a key value). \n",
    "\n",
    "**Sets**: Use these when you need to test for membership in a collection of items. Note: dictionaries can work well for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 328.26 MiB, increment: 174.39 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "## Create some example data\n",
    "import random\n",
    "LIST1 = random.sample(xrange(1000000), 1000000)\n",
    "DICT1 = dict([(i,idx) for idx, i in enumerate(LIST1)])\n",
    "SET1 = set(LIST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501355\n",
      "Elapsed time for list: 0.031 seconds\n",
      "\n",
      "501355\n",
      "Elapsed time for dictionary: 0.000 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## How long does it take to find an item?\n",
    "## Using a list\n",
    "t0 = time.time()\n",
    "idx = LIST1.index(567890)\n",
    "print idx\n",
    "print \"Elapsed time for list: %.3f seconds\\n\" % (time.time()-t0,)\n",
    "\n",
    "## Using a dictionary\n",
    "t0 = time.time()\n",
    "idx = DICT1[567890]\n",
    "print idx\n",
    "print \"Elapsed time for dictionary: %.3f seconds\\n\" % (time.time()-t0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.2 ms, sys: 725 µs, total: 32.9 ms\n",
      "Wall time: 33 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "501355"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time LIST1.index(567890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "501355"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time DICT1[567890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List: \n",
      "CPU times: user 31.2 ms, sys: 76 µs, total: 31.3 ms\n",
      "Wall time: 31.3 ms\n",
      "Dictionary: \n",
      "CPU times: user 4 µs, sys: 4 µs, total: 8 µs\n",
      "Wall time: 8.82 µs\n",
      "Set: \n",
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How long does it take to determine if an item exists?\n",
    "x = 567890\n",
    "## Using a list\n",
    "print \"List: \"\n",
    "%time x in LIST1\n",
    "\n",
    "## Using a dictionary\n",
    "print \"Dictionary: \"\n",
    "%time x in DICT1\n",
    "\n",
    "## Using a set\n",
    "print \"Set: \"\n",
    "%time x in SET1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbSNP Dataset\n",
    "\n",
    "For the following examples, we'll be using data from dbSNP, which contains information about all single nucleotide polymorphisms (SNPs) on human chromosome 1. The data file is a tab-delimited text file containing four columns: the 'rs' number of the SNP, the chromosome, the position, and a comma-separated list of genes at the same location. Note: the file contains a multi-line header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbSNP Chromosome Report\r\n",
      "Refer to ftp://ftp.ncbi.nlm.nih.gov/snp/00readme for documentation on tabular data below\r\n",
      "\r\n",
      "rs#\tchr\tchr\tlocal\r\n",
      "\t\tpos\tloci\r\n",
      "\r\n",
      "\r\n",
      "171\t1\t175261679\t\r\n",
      "242\t1\t20869461\t\r\n",
      "538\t1\t6160958\tKCNAB2\r\n"
     ]
    }
   ],
   "source": [
    "!head ./data/chr1_reducedCols.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Relational DBs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following MySQL examples assume a local database server, with a database called 'bmi535'. The following commands were run to create a table and load data:\n",
    "\n",
    "    CREATE TABLE snps (rs int(10), \n",
    "                       chr int(10), \n",
    "                       pos int(10), \n",
    "                       loci varchar(80));\n",
    "    \n",
    "    LOAD DATA LOCAL INFILE '~/Documents/BMI535/Lectures/data/chr1_reducedCols.txt' \n",
    "    INTO TABLE snps FIELDS TERMINATED BY '\\t' LINES TERMINATED BY '\\n'\n",
    "    IGNORE 7 LINES (rs, chr, pos, loci);\n",
    "    \n",
    "The following command was run to clean cases of missing data (un-mapped SNPs):\n",
    "\n",
    "    UPDATE snps SET pos = NULL WHERE pos = 0;\n",
    "\n",
    "I've also created a second table with the same data, but this time I've created an index on the 'pos' column.\n",
    "\n",
    "    CREATE TABLE snps_idx SELECT * FROM snps;\n",
    "    \n",
    "    CREATE INDEX pos ON snps_idx (pos); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import database connection settings\n",
    "import mysqlconfig as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the MySQL database\n",
    "## Note: the 'cursorclass' parameter is optional, in this case it specifies\n",
    "## that query results will be returned as dictionaries, rather than the default tuples\n",
    "conn = pym.connect(host=cfg.mysql['host'], user=cfg.mysql['user'], password=cfg.mysql['password'], \n",
    "                   database=cfg.mysql['db'], cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'chr': 1, u'loci': 'DNAH14', u'pos': 225512846, u'rs': 189425743}\n",
      "CPU times: user 1.53 ms, sys: 1.85 ms, total: 3.38 ms\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"SELECT * FROM snps WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn as c:\n",
    "    with c as cur:\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchone()\n",
    "        print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'chr': 1, u'loci': 'DNAH14', u'pos': 225512846, u'rs': 189425743}\n",
      "CPU times: user 1.35 ms, sys: 1.1 ms, total: 2.45 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Now let's look at how an indexed table affects performance\n",
    "query = \"SELECT * FROM snps_idx WHERE chr = 1 AND pos = 225512846 AND loci = 'DNAH14';\"\n",
    "with conn as c:\n",
    "    with c as cur:\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchone()\n",
    "        print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note: you can use the following connection attribute to test if the connection is open\n",
    "conn.open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas ...\n",
    "\n",
    "### Load Data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1493.11 MiB, increment: 1222.81 MiB\n"
     ]
    }
   ],
   "source": [
    "## Load SNP Data\n",
    "## Note we can load data directly from a compressed file (gzip)\n",
    "%memit snps = pd.read_csv('./data/chr1_reducedCols.txt.gz', compression='gzip', sep='\\t', header=None, skiprows=7, names=['rs','chr','pos','loci'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12237943, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the dimensions of the dataframe\n",
    "snps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     object\n",
      "loci    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "## Print info about the data (data types, etc.)\n",
    "snps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr        pos    loci\n",
       "0  171    1  175261679     NaN\n",
       "1  242    1   20869461     NaN\n",
       "2  538    1    6160958  KCNAB2\n",
       "3  546    1   93617546   TMED5\n",
       "4  549    1   15546825  TMEM51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print the first few rows of the data\n",
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do some data cleaning ...\n",
    "## Since some SNP positions were missing (spaces), make sure to convert\n",
    "## the column to numeric data.\n",
    "## Also, fill NaNs in the loci column with empty strings. This will improve \n",
    "## compatability with other Python modules (e.g. conversion of data types)\n",
    "snps['pos'] = pd.to_numeric(snps['pos'], errors='coerce', downcast='integer')\n",
    "snps = snps.fillna({'loci':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>175261679.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>20869461.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>6160958.0</td>\n",
       "      <td>KCNAB2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>93617546.0</td>\n",
       "      <td>TMED5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>15546825.0</td>\n",
       "      <td>TMEM51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rs  chr          pos    loci\n",
       "0  171    1  175261679.0        \n",
       "1  242    1   20869461.0        \n",
       "2  538    1    6160958.0  KCNAB2\n",
       "3  546    1   93617546.0   TMED5\n",
       "4  549    1   15546825.0  TMEM51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12237943 entries, 0 to 12237942\n",
      "Data columns (total 4 columns):\n",
      "rs      int64\n",
      "chr     int64\n",
      "pos     float64\n",
      "loci    object\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "snps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 403 ms, sys: 141 ms, total: 543 ms\n",
      "Wall time: 568 ms\n"
     ]
    }
   ],
   "source": [
    "%time pandas_result = snps.query(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>loci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3456788</th>\n",
       "      <td>189425743</td>\n",
       "      <td>1</td>\n",
       "      <td>225512846.0</td>\n",
       "      <td>DNAH14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rs  chr          pos    loci\n",
       "3456788  189425743    1  225512846.0  DNAH14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to HDF5 for Use Later\n",
    "\n",
    "**Pandas has some confusing documentation when it comes to creating HDF5 files from dataframes (the `to_hdf()` method). According to the docs, the `data_columns` parameter is meant to specify what columns should be indexed in the HDF5 file (PyTables format only). It does do this, but it also uses this parameter to specify which columns are able to be (easily) queried in the HDF5 table. And ultimately, whether or not indexes are created is controlled by the `index` parameter. As I see it, you should always use `data_columns=True` so you can always query all columns, but control indexing with the `index` parameter (and actually it is probably better to create indexes later, as needed, using the PyTables module; see below). Creating indexes on all columns is costly and probably unnecessary in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Use index=False to avoid creating any indexes in the HDF5 file.\n",
    "%time snps.to_hdf('./data/snps_pandas_hdf.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='blosc:lz4', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./data/snps_pandas_hdf.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save an HDF5 with zlib compression for compatibility with R\n",
    "## This is much slower than above, so I've lowered the compression level\n",
    "%time snps.to_hdf('./data/snps_pandas_hdf_zlib.h5', mode='w', key='/snps', format='table', data_columns=True, index=False, complib='zlib', complevel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./data/snps_pandas_hdf_zlib.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bcolz\n",
    "\n",
    "Bcolz is a Python module for storing large data sets on-disk or in memory with compression. \n",
    "\n",
    "### Load Data into a Bcolz ctable (in-memory)\n",
    "\n",
    "Bcolz Tutorials:\n",
    "[http://bcolz.readthedocs.io/en/latest/tutorial.html](http://bcolz.readthedocs.io/en/latest/tutorial.html)\n",
    "\n",
    "****Note**: If your dataframe has a string column with missing values (NaNs), the conversion to a Bcolz ctable may be very slow. You should fill-in the NaNs with empty strings (or some other value) so that Bcolz can more easily convert the Pandas 'object' data type to fixed length strings (we did this above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "bcolz version:     1.1.2\n",
      "NumPy version:     1.13.3\n",
      "Blosc version:     1.11.2 ($Date:: 2017-01-27 #$)\n",
      "Blosc compressors: ['blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib', 'zstd']\n",
      "Numexpr version:   2.6.2\n",
      "Dask version:      0.15.0\n",
      "Python version:    2.7.11 |Anaconda custom (x86_64)| (default, Dec  6 2015, 18:57:58) \n",
      "[GCC 4.2.1 (Apple Inc. build 5577)]\n",
      "Platform:          darwin-x86_64\n",
      "Byte-ordering:     little\n",
      "Detected cores:    8\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get info about Bcolz and set some parameters\n",
    "bcolz.print_versions()\n",
    "bcolz.defaults.cparams['cname'] = 'lz4'\n",
    "bcolz.defaults.cparams['clevel'] = 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.BITSHUFFLE\n",
    "bcolz.set_nthreads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/bcolz/ctable.py:693: FutureWarning: pandas.lib is deprecated and will be removed in a future version.\n",
      "You can access infer_dtype as pandas.api.types.infer_dtype\n",
      "  inferred_type = pd.lib.infer_dtype(vals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3129.13 MiB, increment: 1229.25 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit snps_bcolz1 = bcolz.ctable.fromdataframe(snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(171, 1,   1.75261679e+08, ''), (242, 1,   2.08694610e+07, ''),\n",
       "       (538, 1,   6.16095800e+06, 'KCNAB2'),\n",
       "       (546, 1,   9.36175460e+07, 'TMED5'),\n",
       "       (549, 1,   1.55468250e+07, 'TMEM51')],\n",
       "      dtype=[('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Indexing is much like numpy\n",
    "snps_bcolz1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'KCNAB2',\n",
       " 'TMED5',\n",
       " 'TMEM51',\n",
       " 'ATP2B4',\n",
       " 'FUCA1',\n",
       " 'C1orf123,CPT2',\n",
       " 'SERPINC1',\n",
       " '']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can also easily iterate over a ctable\n",
    "## Here we are iterating over the first 10 rows\n",
    "[row.loci for row in snps_bcolz1.iter(0,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into a Bcolz ctable (on-disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an on-disk Bcolz ctable from a Pandas DataFrame\n",
    "## First check that the data directory is empty\n",
    "bcolz_dir = './data/bcolz_data'\n",
    "if os.path.exists(bcolz_dir):\n",
    "    shutil.rmtree(bcolz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2748.48 MiB, increment: 1005.21 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "snps_bcolz2 = bcolz.ctable.fromdataframe(snps, rootdir=bcolz_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1746.95 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182M\t./data/bcolz_data\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh $bcolz_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Bcolz (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 s, sys: 25.2 ms, total: 1.32 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%time bcolz_result = snps_bcolz1[\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(189425743, 1,   2.25512846e+08, 'DNAH14')],\n",
       "      dtype=(numpy.record, [('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Query Using Bcolz (on-disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 130 ms, total: 1.52 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%time bcolz_result = snps_bcolz2[\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(189425743, 1,   2.25512846e+08, 'DNAH14')],\n",
       "      dtype=(numpy.record, [('rs', '<i8'), ('chr', '<i8'), ('pos', '<f8'), ('loci', 'S76')]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 125 ms, total: 1.54 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "## Another way to query the bcolz ctable\n",
    "%time bcolz_result2 = [row for row in snps_bcolz2.where(\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[row(rs=189425743, chr=1, pos=225512846.0, loci='DNAH14')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save to HDF5 for Use Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note this will use the cparams specified above (i.e. same compression as Pandas)\n",
    "%time snps_bcolz.tohdf5('./data/snps_bcolz_hdf.h5', mode='w', nodepath='/snps', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh ./data/snps_bcolz_hdf.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bcolz carrays and `bdot`\n",
    "\n",
    "`carrays` are very similar to numpy multi-dimensional arrays (ndarrays), but have features such as compression and on-disk storage that make them useful for large data sets. They are good for homogeneous data, in contrast to `ctables` (above), which are better for heterogeneous data tables.\n",
    "\n",
    "The `bdot` module is built on Bcolz and allows for fast dot products on carrays.\n",
    "\n",
    "https://github.com/tailwind/bdot\n",
    "\n",
    "Other resources for further reading:\n",
    "\n",
    "Blaze: [http://blaze.pydata.org/](http://blaze.pydata.org/)\n",
    "\n",
    "Dask: [https://dask.pydata.org/en/latest/](https://dask.pydata.org/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an on-disk Bcolz carray from a numpy ndarray\n",
    "## First check that the data directory is empty\n",
    "bcolz_dir2 = './data/bcolz_data2'\n",
    "if os.path.exists(bcolz_dir2):\n",
    "    shutil.rmtree(bcolz_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "carray1 = bdot.carray(np.random.uniform(0, 1, size=(10000, 100)), rootdir=bcolz_dir2)\n",
    "carray1.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.6M\t./data/bcolz_data2\r\n"
     ]
    }
   ],
   "source": [
    "## How much space is used on disk?\n",
    "!du -sh $bcolz_dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carray1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14734498,  0.82226933,  0.21698654,  0.35471016,  0.63703963],\n",
       "       [ 0.34430996,  0.29680343,  0.64645604,  0.05586492,  0.66312949],\n",
       "       [ 0.06034305,  0.09151643,  0.76518275,  0.92991039,  0.06438756],\n",
       "       [ 0.08673422,  0.04884272,  0.45266602,  0.6098255 ,  0.22949568],\n",
       "       [ 0.25815289,  0.32575835,  0.62686822,  0.94105001,  0.82776109]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carray1[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create another carray with just the first row\n",
    "v = carray1[0]\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1766.63 MiB, increment: -0.50 MiB\n"
     ]
    }
   ],
   "source": [
    "## Perform a dot product \n",
    "%memit x = carray1.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTables\n",
    "\n",
    "PyTables is a Python module that provides an interface to the HDF5 library. It extends the basic HDF5 functionality to allow for improved querying...\n",
    "\n",
    "[http://www.pytables.org/usersguide/tutorials.html](http://www.pytables.org/usersguide/tutorials.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 from Pandas (PyTables format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set filename and determine whether the file is in PyTables format\n",
    "pandas_hdf5 = './data/snps_pandas_hdf.h5'\n",
    "tables.is_pytables_file(pandas_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "## Let's load the HDF5 file exported by Pandas\n",
    "h5file = tables.open_file(pandas_hdf5)\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  }"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Is the table indexed?\n",
    "h5_snps_pandas.table.colindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 s, sys: 101 ms, total: 3.95 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "## Let's search the HDF5 file\n",
    "## The first column in the table is an index; I'm excluding it from the results\n",
    "%time pytables_result = [row[1:] for row in h5_snps_pandas.table.iterrows() if row['chr']==1 and row['pos']==225512846 and row['loci']=='DNAH14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 45.9 ms, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "## Now let's run a query using the PyTables in-kernel method\n",
    "%time pytables_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytables_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 from Bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcolz_hdf5 = './data/snps_bcolz_hdf.h5'\n",
    "tables.is_pytables_file(bcolz_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## And now the HDF5 file exported by bcolz\n",
    "bcolz_hdf5 = './data/snps_bcolz_hdf.h5'\n",
    "h5file2 = tables.open_file(bcolz_hdf5)\n",
    "h5_snps_bcolz = h5file2.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (5242,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_snps_bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  }"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_snps_bcolz.colindexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 s, sys: 48.7 ms, total: 3.78 s\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "## Let's search the HDF5 file (from Bcolz)\n",
    "%time hdf5_result = [row[:] for row in h5_snps_bcolz.iterrows() if row['chr']==1 and row['pos']==225512846 and row['loci']=='DNAH14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 48.1 ms, total: 1.13 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "## Now let's run a query using the PyTables in-kernel method (again, on the Bcolz HDF5 file)\n",
    "%time hdf5_result2 = [row[:] for row in h5_snps_bcolz.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Are any files still open?\n",
    "len(tables.file._open_files.get_handlers_by_name('./data/snps_pandas_hdf.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If so, close them\n",
    "tables.file._open_files.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTables: Creating an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the file in append mode\n",
    "h5file = tables.open_file(pandas_hdf5, mode='a')\n",
    "h5_snps_pandas = h5file.root.snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's take a look at the table\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 738 ms, total: 27.7 s\n",
      "Wall time: 28.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12237943"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now create the index\n",
    "## Note: a csindex (completely sorted) is the most optimized index\n",
    "## and therefore is likely to take longer to create and consume\n",
    "## more disk space. You can create other types of indexes with\n",
    "## the create_index() method\n",
    "%time h5_snps_pandas.table.cols.pos.create_csindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/snps/table (Table(12237943,), shuffle, blosc:lz4(9)) ''\n",
       "  description := {\n",
       "  \"index\": Int64Col(shape=(), dflt=0, pos=0),\n",
       "  \"rs\": Int64Col(shape=(), dflt=0, pos=1),\n",
       "  \"chr\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"pos\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"loci\": StringCol(itemsize=76, shape=(), dflt='', pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (4854,)\n",
       "  autoindex := True\n",
       "  colindexes := {\n",
       "    \"pos\": Index(9, full, shuffle, zlib(1)).is_csi=True}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now you should see that an index has been added\n",
    "h5_snps_pandas.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'pos'})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine whether your query will use an index\n",
    "## This will return the column name whose index is usable, or\n",
    "## an empty set if none\n",
    "h5_snps_pandas.table.will_query_use_indexing(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 ms, sys: 3.06 ms, total: 8.81 ms\n",
      "Wall time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "## Let's run a query using the PyTables in-kernel method (now using an index)\n",
    "%time pandas_result2 = [row[1:] for row in h5_snps_pandas.table.where(\"\"\"(chr==1) & (pos==225512846) & (loci=='DNAH14')\"\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****This is nearly as good as using the indexed MySQL table!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(189425743, 1, 225512846.0, 'DNAH14')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close the file\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did we learn?\n",
    "\n",
    "- Some basic ways to measure the performance (i.e. the resources used) of computational tasks\n",
    "- There are multiple solutions for storing large datasets in Python, each with different capabilities\n",
    "- Indexing can greatly improve query performance\n",
    "\n",
    "### A Quick Summary\n",
    "\n",
    "- For storing data in memory:\n",
    "    - Pandas (Numpy)\n",
    "    - Bcolz\n",
    "- For storing data on-disk:\n",
    "    - Bcolz\n",
    "    - HDF5 (PyTables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 1.\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise 2.\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Updated: 25-Oct-2017"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
